# AI智能小说生成器 - 自定义大模型配置示例
# 复制此文件为 .env 并根据您的实际情况修改配置

# =============================================================================
# 基本配置
# =============================================================================
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO
LOG_FORMAT=json

# =============================================================================
# API服务配置
# =============================================================================
HOST=0.0.0.0
PORT=8000
API_RELOAD=true
API_WORKERS=1

# =============================================================================
# 数据库配置
# =============================================================================
DATABASE_URL=sqlite+aiosqlite:///./ai_novel_generator.db
DATABASE_ECHO=false

# =============================================================================
# LLM提供商配置
# =============================================================================

# 主要LLM提供商 (openai, ollama, custom)
PRIMARY_LLM_PROVIDER=custom

# 后备LLM提供商 (用逗号分隔)
FALLBACK_LLM_PROVIDERS=ollama,openai

# LLM重试配置
LLM_RETRY_ATTEMPTS=3
LLM_RETRY_DELAY=2
LLM_REQUEST_TIMEOUT=120

# LLM速率限制配置
LLM_RATE_LIMIT_DELAY=10.0  # LLM调用之间的最小间隔（秒）
LLM_MAX_RETRIES=3          # LLM调用最大重试次数

# =============================================================================
# OpenAI配置 (如果使用)
# =============================================================================
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_MAX_TOKENS=4000
OPENAI_TEMPERATURE=0.7
OPENAI_BASE_URL=https://api.openai.com/v1

# =============================================================================
# Ollama配置 (本地部署)
# =============================================================================
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2:13b-chat
OLLAMA_TIMEOUT=300
OLLAMA_MAX_TOKENS=4000
OLLAMA_TEMPERATURE=0.7

# =============================================================================
# 自定义模型配置 ⭐ 重点配置
# =============================================================================

# 自定义模型API地址 (必填)
# 示例: https://your-api-endpoint.com/v1 或 http://localhost:8080/v1
CUSTOM_MODEL_BASE_URL=http://localhost:8080/v1

# 自定义模型API密钥 (如果需要)
# 如果您的API不需要密钥，可以留空或设置为 none
CUSTOM_MODEL_API_KEY=your_custom_api_key_here

# 自定义模型名称
# 这是发送给API的模型名称参数
CUSTOM_MODEL_NAME=your-model-name

# 自定义模型超时时间 (秒)
CUSTOM_MODEL_TIMEOUT=300

# =============================================================================
# 性能配置
# =============================================================================
MAX_CONCURRENT_GENERATIONS=3
MAX_WORD_COUNT=200000
MIN_WORD_COUNT=1000
DEFAULT_WORD_COUNT=10000

# 生成超时设置 (秒)
GENERATION_TIMEOUT=7200
CHAPTER_GENERATION_TIMEOUT=600
CONCEPT_EXPANSION_TIMEOUT=120

# =============================================================================
# 缓存配置
# =============================================================================
CACHE_ENABLED=true
REQUEST_CACHE_ENABLED=true
REQUEST_CACHE_TTL=1800
GENERATION_CACHE_ENABLED=true
GENERATION_CACHE_TTL=86400

# =============================================================================
# 日志配置
# =============================================================================
LOG_FILE=logs/ai_novel_generator.log
LOG_ROTATION=daily
LOG_RETENTION_DAYS=30

# =============================================================================
# CORS配置
# =============================================================================
ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000,http://localhost:8000
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000,http://localhost:8000
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=GET,POST,PUT,DELETE,OPTIONS
CORS_ALLOW_HEADERS=*

# =============================================================================
# 功能开关
# =============================================================================
FEATURE_MULTI_VOLUME_GENERATION=true
EXPERIMENTAL_STREAMING_RESPONSE=true
QUALITY_CHECK_ENABLED=true
METRICS_ENABLED=true