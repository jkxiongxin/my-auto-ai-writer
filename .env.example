# ===========================================
# AI Novel Generator Environment Configuration
# ===========================================

# Development Environment
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=DEBUG

# Database Configuration
DATABASE_URL=sqlite:///./ai_novel_generator.db
DATABASE_ECHO=false

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true
API_WORKERS=1

# Security
SECRET_KEY=your-secret-key-here-change-in-production
ACCESS_TOKEN_EXPIRE_MINUTES=30
ALGORITHM=HS256

# LLM Provider Configuration
# ===========================================

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_MAX_TOKENS=4000
OPENAI_TEMPERATURE=0.7
OPENAI_BASE_URL=https://api.openai.com/v1

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2:13b-chat
OLLAMA_TIMEOUT=300
OLLAMA_MAX_TOKENS=4000
OLLAMA_TEMPERATURE=0.7

# Custom Model Configuration
CUSTOM_MODEL_BASE_URL=http://localhost:8080
CUSTOM_MODEL_API_KEY=your-custom-model-api-key
CUSTOM_MODEL_NAME=custom-model-v1
CUSTOM_MODEL_TIMEOUT=300

# LLM Router Configuration
PRIMARY_LLM_PROVIDER=openai
FALLBACK_LLM_PROVIDERS=ollama,custom
LLM_RETRY_ATTEMPTS=3
LLM_RETRY_DELAY=1
LLM_REQUEST_TIMEOUT=60

# Cache Configuration
# ===========================================
REDIS_URL=redis://localhost:6379/0
CACHE_TTL=3600
CACHE_ENABLED=true

# Request Cache
REQUEST_CACHE_ENABLED=true
REQUEST_CACHE_TTL=1800
REQUEST_CACHE_MAX_SIZE=1000

# Generation Cache
GENERATION_CACHE_ENABLED=true
GENERATION_CACHE_TTL=86400
GENERATION_CACHE_MAX_SIZE=100

# Performance Configuration
# ===========================================

# Generation Limits
MAX_CONCURRENT_GENERATIONS=3
MAX_WORD_COUNT=200000
MIN_WORD_COUNT=1000
DEFAULT_WORD_COUNT=10000

# Timeout Settings
GENERATION_TIMEOUT=7200
CHAPTER_GENERATION_TIMEOUT=600
CONCEPT_EXPANSION_TIMEOUT=120

# Quality Control
MIN_COHERENCE_SCORE=6.0
MIN_CHARACTER_CONSISTENCY=0.7
QUALITY_CHECK_ENABLED=true

# Monitoring & Logging
# ===========================================

# Prometheus Metrics
METRICS_ENABLED=true
METRICS_PORT=9090
METRICS_PATH=/metrics

# Structured Logging
LOG_FORMAT=json
LOG_FILE=logs/ai_novel_generator.log
LOG_ROTATION=daily
LOG_RETENTION_DAYS=30

# Error Tracking
SENTRY_DSN=your-sentry-dsn-here
SENTRY_ENVIRONMENT=development
SENTRY_TRACES_SAMPLE_RATE=0.1

# File Storage
# ===========================================
UPLOAD_DIR=data/uploads
EXPORT_DIR=data/exports
SAMPLES_DIR=data/samples
TEMPLATES_DIR=data/templates

# File Size Limits (in bytes)
MAX_UPLOAD_SIZE=10485760  # 10MB
MAX_EXPORT_SIZE=52428800  # 50MB

# Rate Limiting
# ===========================================
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS_PER_MINUTE=60
RATE_LIMIT_BURST_SIZE=10

# Generation Rate Limits
GENERATION_RATE_LIMIT_PER_HOUR=10
GENERATION_RATE_LIMIT_PER_DAY=50

# CORS Configuration
# ===========================================
CORS_ORIGINS=["http://localhost:3000", "http://127.0.0.1:3000"]
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=["GET", "POST", "PUT", "DELETE", "OPTIONS"]
CORS_ALLOW_HEADERS=["*"]

# Testing Configuration
# ===========================================
TEST_DATABASE_URL=sqlite:///./test_ai_novel_generator.db
TEST_OPENAI_API_KEY=test-key
TEST_MOCK_LLM_RESPONSES=true
TEST_SKIP_SLOW_TESTS=true

# Feature Flags
# ===========================================
FEATURE_MULTI_VOLUME_GENERATION=true
FEATURE_ADVANCED_CHARACTER_SYSTEM=false
FEATURE_REAL_TIME_COLLABORATION=false
FEATURE_VOICE_NARRATION=false
FEATURE_IMAGE_GENERATION=false

# Experimental Features
EXPERIMENTAL_BATCH_GENERATION=false
EXPERIMENTAL_STREAMING_RESPONSE=true
EXPERIMENTAL_AUTO_EDITING=false