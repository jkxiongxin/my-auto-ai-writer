#!/usr/bin/env python3
"""é›†æˆå’Œç«¯åˆ°ç«¯æµ‹è¯•è¿è¡Œè„šæœ¬

æ­¤è„šæœ¬è¿è¡Œå®Œæ•´çš„é›†æˆæµ‹è¯•å¥—ä»¶ï¼ŒåŒ…æ‹¬ï¼š
- é›†æˆæµ‹è¯•
- æ€§èƒ½æµ‹è¯•
- éªŒæ”¶æµ‹è¯•
"""

import os
import sys
import time
import subprocess
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def run_command(command, description):
    """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
    print(f"\n{'='*60}")
    print(f"ğŸš€ {description}")
    print(f"{'='*60}")
    print(f"æ‰§è¡Œå‘½ä»¤: {command}")
    
    start_time = time.time()
    try:
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            cwd=project_root
        )
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"è€—æ—¶: {duration:.2f}ç§’")
        
        if result.returncode == 0:
            print("âœ… æˆåŠŸ")
            if result.stdout:
                print("è¾“å‡º:")
                print(result.stdout)
        else:
            print("âŒ å¤±è´¥")
            if result.stderr:
                print("é”™è¯¯:")
                print(result.stderr)
            if result.stdout:
                print("è¾“å‡º:")
                print(result.stdout)
        
        return result.returncode == 0
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        return False

def check_prerequisites():
    """æ£€æŸ¥è¿è¡Œå‰ææ¡ä»¶"""
    print("ğŸ” æ£€æŸ¥è¿è¡Œå‰ææ¡ä»¶...")
    
    # æ£€æŸ¥Pythonç¯å¢ƒ
    python_version = sys.version_info
    if python_version < (3, 8):
        print(f"âŒ Pythonç‰ˆæœ¬è¿‡ä½: {python_version.major}.{python_version.minor}")
        print("éœ€è¦Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬")
        return False
    
    print(f"âœ… Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    # æ£€æŸ¥é¡¹ç›®ç»“æ„
    required_dirs = [
        "src",
        "tests",
        "tests/integration",
        "tests/performance", 
        "tests/acceptance"
    ]
    
    for dir_path in required_dirs:
        if not (project_root / dir_path).exists():
            print(f"âŒ ç¼ºå°‘ç›®å½•: {dir_path}")
            return False
    
    print("âœ… é¡¹ç›®ç»“æ„å®Œæ•´")
    
    # æ£€æŸ¥æ ¸å¿ƒæ–‡ä»¶
    required_files = [
        "src/core/novel_generator.py",
        "tests/integration/test_novel_generation_flow.py",
        "tests/performance/test_performance.py",
        "tests/acceptance/test_final_acceptance.py"
    ]
    
    for file_path in required_files:
        if not (project_root / file_path).exists():
            print(f"âŒ ç¼ºå°‘æ–‡ä»¶: {file_path}")
            return False
    
    print("âœ… æ ¸å¿ƒæ–‡ä»¶å®Œæ•´")
    
    return True

def run_integration_tests():
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    commands = [
        (
            "python -m pytest tests/integration/ -v --tb=short",
            "é›†æˆæµ‹è¯•"
        ),
        (
            "python -m pytest tests/integration/test_novel_generation_flow.py::TestNovelGenerationFlow::test_complete_short_story_generation -v",
            "çŸ­ç¯‡å°è¯´ç”Ÿæˆæµ‹è¯•"
        ),
        (
            "python -m pytest tests/integration/test_novel_generation_flow.py::TestNovelGenerationFlow::test_error_recovery -v",
            "é”™è¯¯æ¢å¤æµ‹è¯•"
        )
    ]
    
    results = []
    for command, description in commands:
        success = run_command(command, description)
        results.append((description, success))
    
    return results

def run_performance_tests():
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    commands = [
        (
            "python -m pytest tests/performance/ -v --tb=short -m 'performance and not slow'",
            "åŸºç¡€æ€§èƒ½æµ‹è¯•"
        ),
        (
            "python -m pytest tests/performance/test_performance.py::TestPerformance::test_generation_speed_benchmark -v",
            "ç”Ÿæˆé€Ÿåº¦åŸºå‡†æµ‹è¯•"
        ),
        (
            "python -m pytest tests/performance/test_performance.py::TestPerformance::test_memory_usage -v",
            "å†…å­˜ä½¿ç”¨æµ‹è¯•"
        ),
        (
            "python -m pytest tests/performance/test_performance.py::TestPerformance::test_concurrent_generation -v",
            "å¹¶å‘ç”Ÿæˆæµ‹è¯•"
        )
    ]
    
    results = []
    for command, description in commands:
        success = run_command(command, description)
        results.append((description, success))
    
    return results

def run_acceptance_tests():
    """è¿è¡ŒéªŒæ”¶æµ‹è¯•"""
    commands = [
        (
            "python -m pytest tests/acceptance/ -v --tb=short",
            "éªŒæ”¶æµ‹è¯•"
        ),
        (
            "python -m pytest tests/acceptance/test_final_acceptance.py::TestFinalAcceptance::test_all_success_criteria -v",
            "æˆåŠŸæ ‡å‡†éªŒè¯"
        ),
        (
            "python -m pytest tests/acceptance/test_final_acceptance.py::TestFinalAcceptance::test_functional_requirements -v",
            "åŠŸèƒ½éœ€æ±‚éªŒè¯"
        ),
        (
            "python -m pytest tests/acceptance/test_final_acceptance.py::TestFinalAcceptance::test_final_acceptance_summary -v",
            "æœ€ç»ˆéªŒæ”¶æ€»ç»“"
        )
    ]
    
    results = []
    for command, description in commands:
        success = run_command(command, description)
        results.append((description, success))
    
    return results

def run_slow_tests():
    """è¿è¡Œæ…¢é€Ÿæµ‹è¯•ï¼ˆå¯é€‰ï¼‰"""
    print("\n" + "="*60)
    print("âš ï¸  æ…¢é€Ÿæµ‹è¯•éœ€è¦æ›´é•¿æ—¶é—´ï¼Œæ˜¯å¦è¿è¡Œï¼Ÿ")
    print("åŒ…æ‹¬ï¼šå¤§å‹å°è¯´ç”Ÿæˆæµ‹è¯•ã€å‹åŠ›æµ‹è¯•ç­‰")
    print("="*60)
    
    response = input("è¿è¡Œæ…¢é€Ÿæµ‹è¯•? (y/N): ").strip().lower()
    
    if response not in ['y', 'yes']:
        print("è·³è¿‡æ…¢é€Ÿæµ‹è¯•")
        return []
    
    commands = [
        (
            "python -m pytest tests/integration/ -v --tb=short -m 'slow'",
            "æ…¢é€Ÿé›†æˆæµ‹è¯•"
        ),
        (
            "python -m pytest tests/performance/ -v --tb=short -m 'slow'",
            "æ…¢é€Ÿæ€§èƒ½æµ‹è¯•"
        )
    ]
    
    results = []
    for command, description in commands:
        success = run_command(command, description)
        results.append((description, success))
    
    return results

def generate_report(all_results):
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("\n" + "="*80)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*80)
    
    total_tests = 0
    passed_tests = 0
    
    for category, results in all_results.items():
        if not results:
            continue
            
        print(f"\nğŸ“‹ {category}:")
        print("-" * 40)
        
        for test_name, success in results:
            status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
            print(f"  {test_name}: {status}")
            total_tests += 1
            if success:
                passed_tests += 1
    
    print("\n" + "="*80)
    print(f"ğŸ“ˆ æ€»ä½“ç»“æœ: {passed_tests}/{total_tests} é€šè¿‡ ({passed_tests/total_tests:.1%})")
    
    if passed_tests == total_tests:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼ç³»ç»Ÿé›†æˆæˆåŠŸï¼")
        return True
    elif passed_tests / total_tests >= 0.8:
        print("âœ… å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œç³»ç»ŸåŸºæœ¬å¯ç”¨")
        return True
    else:
        print("âš ï¸ æµ‹è¯•é€šè¿‡ç‡è¾ƒä½ï¼Œéœ€è¦è¿›ä¸€æ­¥å®Œå–„")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ AIæ™ºèƒ½å°è¯´ç”Ÿæˆå™¨ - é›†æˆå’Œç«¯åˆ°ç«¯æµ‹è¯•")
    print("="*80)
    
    # æ£€æŸ¥å‰ææ¡ä»¶
    if not check_prerequisites():
        print("âŒ å‰ææ¡ä»¶æ£€æŸ¥å¤±è´¥")
        sys.exit(1)
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # è¿è¡Œå„ç±»æµ‹è¯•
    all_results = {}
    
    try:
        # é›†æˆæµ‹è¯•
        print("\nğŸ”— å¼€å§‹é›†æˆæµ‹è¯•...")
        all_results["é›†æˆæµ‹è¯•"] = run_integration_tests()
        
        # æ€§èƒ½æµ‹è¯•
        print("\nâš¡ å¼€å§‹æ€§èƒ½æµ‹è¯•...")
        all_results["æ€§èƒ½æµ‹è¯•"] = run_performance_tests()
        
        # éªŒæ”¶æµ‹è¯•
        print("\nâœ… å¼€å§‹éªŒæ”¶æµ‹è¯•...")
        all_results["éªŒæ”¶æµ‹è¯•"] = run_acceptance_tests()
        
        # æ…¢é€Ÿæµ‹è¯•ï¼ˆå¯é€‰ï¼‰
        slow_results = run_slow_tests()
        if slow_results:
            all_results["æ…¢é€Ÿæµ‹è¯•"] = slow_results
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)
    
    # è®¡ç®—æ€»è€—æ—¶
    end_time = time.time()
    total_duration = end_time - start_time
    
    # ç”ŸæˆæŠ¥å‘Š
    success = generate_report(all_results)
    
    print(f"\nâ±ï¸ æ€»è€—æ—¶: {total_duration:.2f}ç§’")
    print("="*80)
    
    if success:
        print("ğŸ¯ é›†æˆæµ‹è¯•å®Œæˆï¼ç³»ç»Ÿå¯ä»¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µã€‚")
        sys.exit(0)
    else:
        print("ğŸ”§ éœ€è¦ä¿®å¤å¤±è´¥çš„æµ‹è¯•é¡¹ç›®ã€‚")
        sys.exit(1)

if __name__ == "__main__":
    main()